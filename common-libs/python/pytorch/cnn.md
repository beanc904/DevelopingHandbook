# 神经网络图像识别(CNN)

## 基本流程

1. 程序输入栅格图像

2. 重复卷积+池化
    - [-] 卷积层(Convolution)
        - 卷积操作就是利用**卷积核（权重矩阵）**在图像上滑动，并进行局部加权求和（内积）。
        - 每个卷积核学习到一种特定模式的响应（例如：水平边缘、垂直边缘等）。
        - 作用在于：特征提取
    - [-] 激活函数(Activation Function)(e.g. ReLU)
        - 加权求和结果通过**非线性激活函数**，增强模型表达能力，避免变成线性模型。
    - [-] 池化层(Pooling)
        - 池化操作是在不增加参数的前提下，降低特征图尺寸。
        - 通常表现为，将图像划分为若干不重叠小块，并从中选取代表值。
            - **最大池化法**：取最大值，保留最强响应。
            - **平均池化法**：取均值，更加平滑。
        - 作用在于：
            - 降低计算复杂度
            - 提高特征的平移鲁棒性
            - 降低过拟合风险

3. 展平(Flatten)

4. 全连接层(Fully Connected)
    - [-] 全连接操作可简单理解为：对 $n$ 层线性函数的不断拟合。
    - [-] 为避免计算过程的线性化，多层之间需要插入激活函数。
    - [-] 内部算法：
        - 激活函数
        - 交叉熵损失
        - 梯度下降

5. 概率分布输出

> [!SUMMARY]
> CNN 通过卷积层乘以可学习的权重矩阵并经过激活函数，提取图像的局部特征（如边缘和轮廓）；随后使用池化层进行降采样，简化数据形式并保留关键特征。在网络末端，将三维特征图展平为一维向量，以输入到全连接层；最终通过 Softmax 层输出类别概率。

## 专有名词

**归一化**: 将数值缩放到统一范围(e.g. 0-1)

**张量（Tensor）**: 在数学中是一个代数对象，描述了与矢量空间相关的代数对象集之间的多重线性映射。
